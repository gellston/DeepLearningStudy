{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러 텐서들의 흐름에 대해 웨이트를 공유하는 레이어에 대해 공부해봅시다. 그 예로서 <br>\n",
    "hA = a * xA + b <br>\n",
    "hB = a * xB + b <br>\n",
    "y = hA * hB <br>\n",
    "관계를 만족시키는 데이터에서 a, b 를 발견해 봅시다. 초기 웨이트에 따라서 학습이 잘 않될 수도 있으므로 여러번 실행해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "xA (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "xB (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shared (Dense)                  (None, 1)            2           xA[0][0]                         \n",
      "                                                                 xB[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "mul (Multiply)                  (None, 1)            0           shared[0][0]                     \n",
      "                                                                 shared[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "800/800 [==============================] - 1s 779us/sample - loss: 4.1343 - val_loss: 3.9995\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 3.6359 - val_loss: 3.4646\n",
      "Epoch 3/200\n",
      "800/800 [==============================] - 0s 246us/sample - loss: 3.1082 - val_loss: 2.9166\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 0s 282us/sample - loss: 2.5691 - val_loss: 2.3654\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 2.0436 - val_loss: 1.8430\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 0s 231us/sample - loss: 1.5555 - val_loss: 1.3586\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 0s 268us/sample - loss: 1.1256 - val_loss: 0.9602\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 0s 269us/sample - loss: 0.7729 - val_loss: 0.6382\n",
      "Epoch 9/200\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 0.5014 - val_loss: 0.4002\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 0s 261us/sample - loss: 0.3072 - val_loss: 0.2392\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 0.1787 - val_loss: 0.1374\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 0.0999 - val_loss: 0.0752\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 0.0544 - val_loss: 0.0409\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 0.0294 - val_loss: 0.0225\n",
      "Epoch 15/200\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 0.0160 - val_loss: 0.0125\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 0.0088 - val_loss: 0.0070\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 0s 228us/sample - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 0s 231us/sample - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 0s 246us/sample - loss: 8.1066e-04 - val_loss: 6.3086e-04\n",
      "Epoch 21/200\n",
      "800/800 [==============================] - 0s 231us/sample - loss: 4.2123e-04 - val_loss: 3.2095e-04\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 2.1157e-04 - val_loss: 1.5840e-04\n",
      "Epoch 23/200\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 1.0223e-04 - val_loss: 7.5208e-05\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 0s 242us/sample - loss: 4.7392e-05 - val_loss: 3.4218e-05\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 2.1039e-05 - val_loss: 1.4630e-05\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 8.8751e-06 - val_loss: 6.0619e-06\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 3.5764e-06 - val_loss: 2.3878e-06\n",
      "Epoch 28/200\n",
      "800/800 [==============================] - 0s 262us/sample - loss: 1.3682e-06 - val_loss: 8.7170e-07\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 0s 261us/sample - loss: 4.9424e-07 - val_loss: 3.0299e-07\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 0s 269us/sample - loss: 1.6862e-07 - val_loss: 9.6988e-08\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 5.3384e-08 - val_loss: 3.0131e-08\n",
      "Epoch 32/200\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 1.6088e-08 - val_loss: 8.6585e-09\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 4.5981e-09 - val_loss: 2.5498e-09\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 0s 262us/sample - loss: 1.2217e-09 - val_loss: 6.2327e-10\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 3.9998e-10 - val_loss: 3.4462e-10\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 3.0007e-10 - val_loss: 2.9764e-10\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 0s 267us/sample - loss: 2.5883e-10 - val_loss: 2.7541e-10\n",
      "Epoch 38/200\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 2.4604e-10 - val_loss: 2.6506e-10\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 0s 266us/sample - loss: 2.3126e-10 - val_loss: 2.3217e-10\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 0s 269us/sample - loss: 1.9413e-10 - val_loss: 1.6726e-10\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 1.5065e-10 - val_loss: 1.6726e-10\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 0s 264us/sample - loss: 1.5065e-10 - val_loss: 1.6726e-10\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 0s 263us/sample - loss: 1.3024e-10 - val_loss: 1.3347e-10\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 0s 278us/sample - loss: 1.2040e-10 - val_loss: 1.3236e-10\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 1.1174e-10 - val_loss: 1.2157e-10\n",
      "Epoch 46/200\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 1.0982e-10 - val_loss: 1.2157e-10\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 9.4779e-11 - val_loss: 9.9094e-11\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 0s 228us/sample - loss: 8.7635e-11 - val_loss: 7.4833e-11\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 6.5871e-11 - val_loss: 7.1140e-11\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 6.3381e-11 - val_loss: 6.9937e-11\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 5.0042e-11 - val_loss: 5.1444e-11\n",
      "Epoch 52/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 4.4672e-11 - val_loss: 4.6794e-11\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 4.2237e-11 - val_loss: 4.6794e-11\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 0s 242us/sample - loss: 4.2237e-11 - val_loss: 4.6794e-11\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 3.4777e-11 - val_loss: 3.8225e-11\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 2.8854e-11 - val_loss: 2.8265e-11\n",
      "Epoch 57/200\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 2.5371e-11 - val_loss: 2.8265e-11\n",
      "Epoch 58/200\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 2.5371e-11 - val_loss: 2.8265e-11\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 0s 263us/sample - loss: 2.4332e-11 - val_loss: 2.4491e-11\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 2.2189e-11 - val_loss: 2.4491e-11\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 249us/sample - loss: 2.2189e-11 - val_loss: 2.4491e-11\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 0s 222us/sample - loss: 2.1378e-11 - val_loss: 2.1678e-11\n",
      "Epoch 63/200\n",
      "800/800 [==============================] - 0s 222us/sample - loss: 1.5147e-11 - val_loss: 9.2146e-12\n",
      "Epoch 64/200\n",
      "800/800 [==============================] - 0s 244us/sample - loss: 8.2170e-12 - val_loss: 9.2146e-12\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 0s 227us/sample - loss: 8.2170e-12 - val_loss: 9.2146e-12\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 8.2170e-12 - val_loss: 9.2146e-12\n",
      "Epoch 67/200\n",
      "800/800 [==============================] - 0s 226us/sample - loss: 8.2170e-12 - val_loss: 9.2146e-12\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 0s 227us/sample - loss: 8.2170e-12 - val_loss: 9.2146e-12\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 0s 242us/sample - loss: 8.2170e-12 - val_loss: 9.2146e-12\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 0s 232us/sample - loss: 8.2170e-12 - val_loss: 9.2146e-12\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 0s 244us/sample - loss: 8.2170e-12 - val_loss: 9.2146e-12\n",
      "Epoch 72/200\n",
      "800/800 [==============================] - 0s 219us/sample - loss: 7.3674e-12 - val_loss: 5.6019e-12\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 0s 228us/sample - loss: 4.9896e-12 - val_loss: 5.3181e-12\n",
      "Epoch 74/200\n",
      "800/800 [==============================] - 0s 229us/sample - loss: 4.8479e-12 - val_loss: 5.3181e-12\n",
      "Epoch 75/200\n",
      "800/800 [==============================] - 0s 228us/sample - loss: 4.8479e-12 - val_loss: 5.3181e-12\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 0s 231us/sample - loss: 4.7514e-12 - val_loss: 5.2300e-12\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 0s 246us/sample - loss: 4.7177e-12 - val_loss: 5.2300e-12\n",
      "Epoch 78/200\n",
      "800/800 [==============================] - 0s 218us/sample - loss: 2.7460e-12 - val_loss: 2.3886e-12\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 2.1941e-12 - val_loss: 2.3886e-12\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 2.1941e-12 - val_loss: 2.3886e-12\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 0s 219us/sample - loss: 2.1941e-12 - val_loss: 2.3886e-12\n",
      "Epoch 82/200\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 2.1623e-12 - val_loss: 2.3310e-12\n",
      "Epoch 83/200\n",
      "800/800 [==============================] - 0s 231us/sample - loss: 2.0909e-12 - val_loss: 2.3310e-12\n",
      "Epoch 84/200\n",
      "800/800 [==============================] - 0s 232us/sample - loss: 2.0909e-12 - val_loss: 2.3310e-12\n",
      "Epoch 85/200\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 1.6548e-12 - val_loss: 1.3110e-12\n",
      "Epoch 86/200\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 1.1894e-12 - val_loss: 1.3110e-12\n",
      "Epoch 87/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 1.1894e-12 - val_loss: 1.3110e-12\n",
      "Epoch 88/200\n",
      "800/800 [==============================] - 0s 227us/sample - loss: 1.1894e-12 - val_loss: 1.3110e-12\n",
      "Epoch 89/200\n",
      "800/800 [==============================] - 0s 234us/sample - loss: 1.1894e-12 - val_loss: 1.3110e-12\n",
      "Epoch 90/200\n",
      "800/800 [==============================] - 0s 219us/sample - loss: 8.3534e-13 - val_loss: 6.1965e-13\n",
      "Epoch 91/200\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 5.6025e-13 - val_loss: 6.1965e-13\n",
      "Epoch 92/200\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 5.6025e-13 - val_loss: 6.1965e-13\n",
      "Epoch 93/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 5.6025e-13 - val_loss: 6.1965e-13\n",
      "Epoch 94/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 5.6025e-13 - val_loss: 6.1965e-13\n",
      "Epoch 95/200\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 5.6025e-13 - val_loss: 6.1965e-13\n",
      "Epoch 96/200\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 5.6025e-13 - val_loss: 6.1965e-13\n",
      "Epoch 97/200\n",
      "800/800 [==============================] - 0s 231us/sample - loss: 5.7378e-13 - val_loss: 7.2151e-13\n",
      "Epoch 98/200\n",
      "800/800 [==============================] - 0s 228us/sample - loss: 3.1801e-13 - val_loss: 2.0304e-13\n",
      "Epoch 99/200\n",
      "800/800 [==============================] - 0s 226us/sample - loss: 1.8167e-13 - val_loss: 2.0304e-13\n",
      "Epoch 100/200\n",
      "800/800 [==============================] - 0s 234us/sample - loss: 1.8167e-13 - val_loss: 2.0304e-13\n",
      "Epoch 101/200\n",
      "800/800 [==============================] - 0s 231us/sample - loss: 1.8167e-13 - val_loss: 2.0304e-13\n",
      "Epoch 102/200\n",
      "800/800 [==============================] - 0s 241us/sample - loss: 1.8167e-13 - val_loss: 2.0304e-13\n",
      "Epoch 103/200\n",
      "800/800 [==============================] - 0s 263us/sample - loss: 1.6976e-13 - val_loss: 1.7488e-13\n",
      "Epoch 104/200\n",
      "800/800 [==============================] - 0s 224us/sample - loss: 1.5549e-13 - val_loss: 1.7488e-13\n",
      "Epoch 105/200\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 1.5549e-13 - val_loss: 1.7488e-13\n",
      "Epoch 106/200\n",
      "800/800 [==============================] - 0s 233us/sample - loss: 1.5549e-13 - val_loss: 1.7488e-13\n",
      "Epoch 107/200\n",
      "800/800 [==============================] - 0s 232us/sample - loss: 1.5549e-13 - val_loss: 1.7488e-13\n",
      "Epoch 108/200\n",
      "800/800 [==============================] - 0s 246us/sample - loss: 7.5173e-14 - val_loss: 3.4227e-14\n",
      "Epoch 109/200\n",
      "800/800 [==============================] - 0s 226us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 110/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 111/200\n",
      "800/800 [==============================] - 0s 238us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 112/200\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 113/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 114/200\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 115/200\n",
      "800/800 [==============================] - 0s 242us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 116/200\n",
      "800/800 [==============================] - 0s 241us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 117/200\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 118/200\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 119/200\n",
      "800/800 [==============================] - 0s 234us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 120/200\n",
      "800/800 [==============================] - 0s 232us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 121/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 122/200\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 123/200\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 124/200\n",
      "800/800 [==============================] - 0s 227us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 125/200\n",
      "800/800 [==============================] - 0s 232us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 126/200\n",
      "800/800 [==============================] - 0s 233us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 127/200\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 128/200\n",
      "800/800 [==============================] - 0s 246us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 129/200\n",
      "800/800 [==============================] - 0s 231us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 130/200\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 131/200\n",
      "800/800 [==============================] - 0s 233us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 132/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 244us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 133/200\n",
      "800/800 [==============================] - 0s 242us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 134/200\n",
      "800/800 [==============================] - 0s 226us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 135/200\n",
      "800/800 [==============================] - 0s 226us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 136/200\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 137/200\n",
      "800/800 [==============================] - 0s 244us/sample - loss: 2.6695e-14 - val_loss: 3.4227e-14\n",
      "Epoch 138/200\n",
      "800/800 [==============================] - 0s 233us/sample - loss: 1.6491e-14 - val_loss: 3.4227e-14\n",
      "Epoch 139/200\n",
      "800/800 [==============================] - 0s 226us/sample - loss: 4.8986e-14 - val_loss: 3.4227e-14\n",
      "Epoch 140/200\n",
      "800/800 [==============================] - 0s 226us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 141/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 1.6826e-14 - val_loss: 3.4227e-14\n",
      "Epoch 142/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 143/200\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 1.8799e-14 - val_loss: 3.4227e-14\n",
      "Epoch 144/200\n",
      "800/800 [==============================] - 0s 226us/sample - loss: 1.5947e-14 - val_loss: 3.4227e-14\n",
      "Epoch 145/200\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 1.6542e-14 - val_loss: 3.4227e-14\n",
      "Epoch 146/200\n",
      "800/800 [==============================] - 0s 242us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 147/200\n",
      "800/800 [==============================] - 0s 246us/sample - loss: 1.6009e-14 - val_loss: 3.4227e-14\n",
      "Epoch 148/200\n",
      "800/800 [==============================] - 0s 264us/sample - loss: 2.0237e-14 - val_loss: 3.4227e-14\n",
      "Epoch 149/200\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 1.7194e-14 - val_loss: 3.4227e-14\n",
      "Epoch 150/200\n",
      "800/800 [==============================] - 0s 234us/sample - loss: 2.8763e-14 - val_loss: 3.4227e-14\n",
      "Epoch 151/200\n",
      "800/800 [==============================] - 0s 226us/sample - loss: 1.6983e-13 - val_loss: 4.9003e-13\n",
      "Epoch 152/200\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 5.7156e-14 - val_loss: 3.4227e-14\n",
      "Epoch 153/200\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 5.9525e-14 - val_loss: 4.9003e-13\n",
      "Epoch 154/200\n",
      "800/800 [==============================] - 0s 227us/sample - loss: 1.2197e-13 - val_loss: 5.6697e-13\n",
      "Epoch 155/200\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 2.1690e-11 - val_loss: 3.3313e-12\n",
      "Epoch 156/200\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 2.9874e-10 - val_loss: 1.2584e-10\n",
      "Epoch 157/200\n",
      "800/800 [==============================] - 0s 259us/sample - loss: 1.8103e-09 - val_loss: 1.1346e-11\n",
      "Epoch 158/200\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 1.4957e-08 - val_loss: 1.8171e-07\n",
      "Epoch 159/200\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 1.2515e-05 - val_loss: 1.5321e-05\n",
      "Epoch 160/200\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 1.5565e-06 - val_loss: 1.5619e-09\n",
      "Epoch 161/200\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 8.9555e-11 - val_loss: 2.5151e-12\n",
      "Epoch 162/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 8.6519e-14 - val_loss: 3.4227e-14\n",
      "Epoch 163/200\n",
      "800/800 [==============================] - 0s 259us/sample - loss: 1.6277e-14 - val_loss: 3.4227e-14\n",
      "Epoch 164/200\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 1.5002e-14 - val_loss: 3.4227e-14\n",
      "Epoch 165/200\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 1.5794e-14 - val_loss: 3.4227e-14\n",
      "Epoch 166/200\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 2.3000e-14 - val_loss: 3.4227e-14\n",
      "Epoch 167/200\n",
      "800/800 [==============================] - 0s 269us/sample - loss: 2.3107e-14 - val_loss: 3.4227e-14\n",
      "Epoch 168/200\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 2.5011e-14 - val_loss: 3.4227e-14\n",
      "Epoch 169/200\n",
      "800/800 [==============================] - 0s 259us/sample - loss: 1.8067e-14 - val_loss: 3.4227e-14\n",
      "Epoch 170/200\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 1.6156e-14 - val_loss: 3.4227e-14\n",
      "Epoch 171/200\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 2.2323e-14 - val_loss: 3.4227e-14\n",
      "Epoch 172/200\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 2.6182e-14 - val_loss: 3.4227e-14\n",
      "Epoch 173/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 8.5073e-14 - val_loss: 2.0304e-13\n",
      "Epoch 174/200\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 2.2169e-13 - val_loss: 3.4227e-14\n",
      "Epoch 175/200\n",
      "800/800 [==============================] - 0s 262us/sample - loss: 4.6118e-13 - val_loss: 9.7090e-13\n",
      "Epoch 176/200\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 1.6720e-12 - val_loss: 1.7492e-12\n",
      "Epoch 177/200\n",
      "800/800 [==============================] - 0s 234us/sample - loss: 9.9541e-12 - val_loss: 2.5222e-12\n",
      "Epoch 178/200\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 8.1223e-11 - val_loss: 1.1978e-09\n",
      "Epoch 179/200\n",
      "800/800 [==============================] - 0s 264us/sample - loss: 5.3473e-09 - val_loss: 1.6568e-09\n",
      "Epoch 180/200\n",
      "800/800 [==============================] - 0s 232us/sample - loss: 1.8880e-10 - val_loss: 1.1517e-11\n",
      "Epoch 181/200\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 2.4251e-10 - val_loss: 1.2457e-09\n",
      "Epoch 182/200\n",
      "800/800 [==============================] - 0s 246us/sample - loss: 3.8243e-09 - val_loss: 1.8355e-08\n",
      "Epoch 183/200\n",
      "800/800 [==============================] - 0s 227us/sample - loss: 1.7708e-07 - val_loss: 1.7019e-08\n",
      "Epoch 184/200\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 1.1588e-06 - val_loss: 1.2208e-06\n",
      "Epoch 185/200\n",
      "800/800 [==============================] - 0s 262us/sample - loss: 1.5382e-07 - val_loss: 9.2606e-09\n",
      "Epoch 186/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 1.9263e-09 - val_loss: 1.0065e-10\n",
      "Epoch 187/200\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 8.5650e-11 - val_loss: 1.2254e-10\n",
      "Epoch 188/200\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 2.9897e-10 - val_loss: 8.8390e-10\n",
      "Epoch 189/200\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 1.1403e-09 - val_loss: 6.1027e-11\n",
      "Epoch 190/200\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 2.0979e-10 - val_loss: 3.3840e-10\n",
      "Epoch 191/200\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 2.1552e-10 - val_loss: 1.0700e-09\n",
      "Epoch 192/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 2.8884e-08 - val_loss: 3.4435e-07\n",
      "Epoch 193/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 1.5274e-06 - val_loss: 1.0101e-06\n",
      "Epoch 194/200\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 1.1114e-07 - val_loss: 6.2737e-09\n",
      "Epoch 195/200\n",
      "800/800 [==============================] - 0s 241us/sample - loss: 1.6350e-08 - val_loss: 2.8589e-08\n",
      "Epoch 196/200\n",
      "800/800 [==============================] - 0s 266us/sample - loss: 3.0009e-09 - val_loss: 7.7679e-10\n",
      "Epoch 197/200\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 3.2004e-10 - val_loss: 4.8645e-10\n",
      "Epoch 198/200\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 8.6119e-10 - val_loss: 6.6043e-10\n",
      "Epoch 199/200\n",
      "800/800 [==============================] - 0s 267us/sample - loss: 1.4515e-10 - val_loss: 6.0981e-10\n",
      "Epoch 200/200\n",
      "800/800 [==============================] - 0s 269us/sample - loss: 8.5482e-10 - val_loss: 4.0343e-08\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared_weights\n",
      " [array([[-1.9999243]], dtype=float32), array([-0.9999565], dtype=float32)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "a = 2; b = 1\n",
    "\n",
    "x_train_A = np.random.rand(1000,1) * 2 - 1\n",
    "x_train_B = np.random.rand(1000,1) * 2 - 1\n",
    "y_train = (a * x_train_A + b) * (a * x_train_B + b)\n",
    "\n",
    "shared_layer = layers.Dense(1, name='shared')\n",
    "\n",
    "xA = layers.Input((1,), name='xA')\n",
    "xB = layers.Input((1,), name='xB')\n",
    "sA = shared_layer(xA)\n",
    "sB = shared_layer(xB)\n",
    "y = layers.Multiply(name='mul')([sA, sB])\n",
    "\n",
    "model = models.Model([xA, xB], y)\n",
    "model.summary()\n",
    "\n",
    "model.compile('adam', 'mse')\n",
    "hist = model.fit([x_train_A, x_train_B], y_train,\n",
    "                 batch_size=8, epochs=200, validation_split=0.2)\n",
    "\n",
    "plt.title('Loss')\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc=0)\n",
    "plt.show()\n",
    "\n",
    "shared_weights = model.get_layer('shared').get_weights()\n",
    "print('shared_weights\\n', shared_weights, '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
