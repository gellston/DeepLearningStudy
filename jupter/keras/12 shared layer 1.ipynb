{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "공유 레이어를 사용하여 <br>\n",
    "hA = sigmoid( a * xA + b ) <br>\n",
    "hB = sigmoid( a * xB + b ) <br>\n",
    "y = c * hA * hB + d <br>\n",
    "관계를 만족시키는 데이터에서 a, b, c, d 를 발견해 봅시다. 초기 웨이트에 따라서 학습이 잘 않될 수도 있으므로 여러번 실행해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "xA (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "xB (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shared (Dense)                  (None, 1)            2           xA[0][0]                         \n",
      "                                                                 xB[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "mul (Multiply)                  (None, 1)            0           shared[0][0]                     \n",
      "                                                                 shared[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "y (Dense)                       (None, 1)            2           mul[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 4\n",
      "Trainable params: 4\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "800/800 [==============================] - 1s 833us/sample - loss: 2.7181 - val_loss: 2.3626\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 0s 269us/sample - loss: 2.2655 - val_loss: 1.9441\n",
      "Epoch 3/200\n",
      "800/800 [==============================] - 0s 272us/sample - loss: 1.8531 - val_loss: 1.5682\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 0s 267us/sample - loss: 1.4854 - val_loss: 1.2392\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 0s 280us/sample - loss: 1.1671 - val_loss: 0.9605\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 0.9022 - val_loss: 0.7367\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 0s 272us/sample - loss: 0.6907 - val_loss: 0.5638\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 0s 262us/sample - loss: 0.5295 - val_loss: 0.4354\n",
      "Epoch 9/200\n",
      "800/800 [==============================] - 0s 278us/sample - loss: 0.4120 - val_loss: 0.3473\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 0.3303 - val_loss: 0.2849\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 0s 282us/sample - loss: 0.2731 - val_loss: 0.2433\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 0s 259us/sample - loss: 0.2332 - val_loss: 0.2134\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 0s 268us/sample - loss: 0.2040 - val_loss: 0.1906\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 0s 264us/sample - loss: 0.1815 - val_loss: 0.1717\n",
      "Epoch 15/200\n",
      "800/800 [==============================] - 0s 262us/sample - loss: 0.1627 - val_loss: 0.1552\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 0s 266us/sample - loss: 0.1464 - val_loss: 0.1400\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 0s 267us/sample - loss: 0.1314 - val_loss: 0.1259\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 0s 274us/sample - loss: 0.1178 - val_loss: 0.1127\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 0s 272us/sample - loss: 0.1052 - val_loss: 0.1006\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 0s 267us/sample - loss: 0.0935 - val_loss: 0.0892\n",
      "Epoch 21/200\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.0827 - val_loss: 0.0787\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 0.0728 - val_loss: 0.0690\n",
      "Epoch 23/200\n",
      "800/800 [==============================] - 0s 268us/sample - loss: 0.0637 - val_loss: 0.0601\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 0s 272us/sample - loss: 0.0554 - val_loss: 0.0520\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 0.0478 - val_loss: 0.0448\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 0s 261us/sample - loss: 0.0410 - val_loss: 0.0383\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 0s 267us/sample - loss: 0.0349 - val_loss: 0.0324\n",
      "Epoch 28/200\n",
      "800/800 [==============================] - 0s 271us/sample - loss: 0.0295 - val_loss: 0.0272\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 0s 267us/sample - loss: 0.0247 - val_loss: 0.0226\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 0s 261us/sample - loss: 0.0205 - val_loss: 0.0188\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 0s 259us/sample - loss: 0.0170 - val_loss: 0.0154\n",
      "Epoch 32/200\n",
      "800/800 [==============================] - 0s 277us/sample - loss: 0.0138 - val_loss: 0.0125\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 0s 267us/sample - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 0s 273us/sample - loss: 0.0090 - val_loss: 0.0081\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 0s 272us/sample - loss: 0.0072 - val_loss: 0.0065\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 0s 266us/sample - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 0s 267us/sample - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 38/200\n",
      "800/800 [==============================] - 0s 288us/sample - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 0s 263us/sample - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 0s 268us/sample - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 0s 263us/sample - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 0s 261us/sample - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 0s 269us/sample - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 0s 272us/sample - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 46/200\n",
      "800/800 [==============================] - 0s 278us/sample - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 9.5144e-04 - val_loss: 9.7214e-04\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 0s 266us/sample - loss: 9.1211e-04 - val_loss: 9.4412e-04\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 8.8691e-04 - val_loss: 9.2790e-04\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 0s 259us/sample - loss: 8.6999e-04 - val_loss: 9.1529e-04\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 0s 271us/sample - loss: 8.5814e-04 - val_loss: 9.0862e-04\n",
      "Epoch 52/200\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 8.4964e-04 - val_loss: 8.9849e-04\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 8.4349e-04 - val_loss: 8.9784e-04\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 8.3643e-04 - val_loss: 8.8632e-04\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 8.3203e-04 - val_loss: 8.8049e-04\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 8.2426e-04 - val_loss: 8.7589e-04\n",
      "Epoch 57/200\n",
      "800/800 [==============================] - 0s 261us/sample - loss: 8.1776e-04 - val_loss: 8.6873e-04\n",
      "Epoch 58/200\n",
      "800/800 [==============================] - 0s 261us/sample - loss: 8.1338e-04 - val_loss: 8.6316e-04\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 8.0491e-04 - val_loss: 8.5601e-04\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 7.9912e-04 - val_loss: 8.4909e-04\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 262us/sample - loss: 7.9312e-04 - val_loss: 8.4511e-04\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 7.8690e-04 - val_loss: 8.3480e-04\n",
      "Epoch 63/200\n",
      "800/800 [==============================] - 0s 244us/sample - loss: 7.7790e-04 - val_loss: 8.2697e-04\n",
      "Epoch 64/200\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 7.6964e-04 - val_loss: 8.2255e-04\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 7.6318e-04 - val_loss: 8.2603e-04\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 7.5667e-04 - val_loss: 8.0231e-04\n",
      "Epoch 67/200\n",
      "800/800 [==============================] - 0s 244us/sample - loss: 7.4776e-04 - val_loss: 7.9906e-04\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 7.4081e-04 - val_loss: 7.8594e-04\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 7.3393e-04 - val_loss: 7.7534e-04\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 0s 242us/sample - loss: 7.2134e-04 - val_loss: 7.6696e-04\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 0s 259us/sample - loss: 7.1117e-04 - val_loss: 7.5598e-04\n",
      "Epoch 72/200\n",
      "800/800 [==============================] - 0s 241us/sample - loss: 7.0347e-04 - val_loss: 7.4904e-04\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 6.9460e-04 - val_loss: 7.3470e-04\n",
      "Epoch 74/200\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 6.8337e-04 - val_loss: 7.2584e-04\n",
      "Epoch 75/200\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 6.7286e-04 - val_loss: 7.1499e-04\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 0s 261us/sample - loss: 6.6281e-04 - val_loss: 7.0470e-04\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 6.5480e-04 - val_loss: 6.8954e-04\n",
      "Epoch 78/200\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 6.3937e-04 - val_loss: 6.7760e-04\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 0s 244us/sample - loss: 6.2920e-04 - val_loss: 6.7769e-04\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 6.2115e-04 - val_loss: 6.5572e-04\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 6.0211e-04 - val_loss: 6.5431e-04\n",
      "Epoch 82/200\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 5.9952e-04 - val_loss: 6.3033e-04\n",
      "Epoch 83/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 5.8793e-04 - val_loss: 6.1660e-04\n",
      "Epoch 84/200\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 5.7013e-04 - val_loss: 6.0486e-04\n",
      "Epoch 85/200\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 5.6040e-04 - val_loss: 5.9631e-04\n",
      "Epoch 86/200\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 5.4829e-04 - val_loss: 5.8390e-04\n",
      "Epoch 87/200\n",
      "800/800 [==============================] - 0s 264us/sample - loss: 5.3305e-04 - val_loss: 5.6620e-04\n",
      "Epoch 88/200\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 5.1895e-04 - val_loss: 5.7679e-04\n",
      "Epoch 89/200\n",
      "800/800 [==============================] - 0s 259us/sample - loss: 5.1105e-04 - val_loss: 5.4375e-04\n",
      "Epoch 90/200\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 4.9709e-04 - val_loss: 5.3629e-04\n",
      "Epoch 91/200\n",
      "800/800 [==============================] - 0s 263us/sample - loss: 4.8496e-04 - val_loss: 5.0995e-04\n",
      "Epoch 92/200\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 4.7324e-04 - val_loss: 4.9799e-04\n",
      "Epoch 93/200\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 4.5724e-04 - val_loss: 4.8272e-04\n",
      "Epoch 94/200\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 4.4514e-04 - val_loss: 4.7777e-04\n",
      "Epoch 95/200\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 4.3863e-04 - val_loss: 4.6400e-04\n",
      "Epoch 96/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 4.2045e-04 - val_loss: 4.4990e-04\n",
      "Epoch 97/200\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 4.1118e-04 - val_loss: 4.2856e-04\n",
      "Epoch 98/200\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 3.9498e-04 - val_loss: 4.1404e-04\n",
      "Epoch 99/200\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 3.8080e-04 - val_loss: 4.0054e-04\n",
      "Epoch 100/200\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 3.6891e-04 - val_loss: 3.8981e-04\n",
      "Epoch 101/200\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 3.5780e-04 - val_loss: 3.9022e-04\n",
      "Epoch 102/200\n",
      "800/800 [==============================] - 0s 262us/sample - loss: 3.4307e-04 - val_loss: 3.5987e-04\n",
      "Epoch 103/200\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 3.3090e-04 - val_loss: 3.5304e-04\n",
      "Epoch 104/200\n",
      "800/800 [==============================] - 0s 246us/sample - loss: 3.2315e-04 - val_loss: 3.3795e-04\n",
      "Epoch 105/200\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 3.0925e-04 - val_loss: 3.2544e-04\n",
      "Epoch 106/200\n",
      "800/800 [==============================] - 0s 266us/sample - loss: 2.9860e-04 - val_loss: 3.0778e-04\n",
      "Epoch 107/200\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 2.8217e-04 - val_loss: 2.9593e-04\n",
      "Epoch 108/200\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 2.7087e-04 - val_loss: 2.8796e-04\n",
      "Epoch 109/200\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 2.5879e-04 - val_loss: 2.8536e-04\n",
      "Epoch 110/200\n",
      "800/800 [==============================] - 0s 250us/sample - loss: 2.4888e-04 - val_loss: 2.5980e-04\n",
      "Epoch 111/200\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 2.3488e-04 - val_loss: 2.4674e-04\n",
      "Epoch 112/200\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 2.2583e-04 - val_loss: 2.3326e-04\n",
      "Epoch 113/200\n",
      "800/800 [==============================] - 0s 244us/sample - loss: 2.1221e-04 - val_loss: 2.2202e-04\n",
      "Epoch 114/200\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 2.0267e-04 - val_loss: 2.1006e-04\n",
      "Epoch 115/200\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 1.9151e-04 - val_loss: 2.0112e-04\n",
      "Epoch 116/200\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 1.8079e-04 - val_loss: 1.8973e-04\n",
      "Epoch 117/200\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 1.7222e-04 - val_loss: 1.8048e-04\n",
      "Epoch 118/200\n",
      "800/800 [==============================] - 0s 264us/sample - loss: 1.6148e-04 - val_loss: 1.6607e-04\n",
      "Epoch 119/200\n",
      "800/800 [==============================] - 0s 246us/sample - loss: 1.5081e-04 - val_loss: 1.5852e-04\n",
      "Epoch 120/200\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 1.4136e-04 - val_loss: 1.4536e-04\n",
      "Epoch 121/200\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 1.3079e-04 - val_loss: 1.3600e-04\n",
      "Epoch 122/200\n",
      "800/800 [==============================] - 0s 267us/sample - loss: 1.2272e-04 - val_loss: 1.2647e-04\n",
      "Epoch 123/200\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 1.1457e-04 - val_loss: 1.1625e-04\n",
      "Epoch 124/200\n",
      "800/800 [==============================] - 0s 262us/sample - loss: 1.0546e-04 - val_loss: 1.0815e-04\n",
      "Epoch 125/200\n",
      "800/800 [==============================] - 0s 246us/sample - loss: 9.7372e-05 - val_loss: 9.8587e-05\n",
      "Epoch 126/200\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 8.8137e-05 - val_loss: 9.4336e-05\n",
      "Epoch 127/200\n",
      "800/800 [==============================] - 0s 268us/sample - loss: 8.3950e-05 - val_loss: 8.3612e-05\n",
      "Epoch 128/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 7.3995e-05 - val_loss: 7.6441e-05\n",
      "Epoch 129/200\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 6.7703e-05 - val_loss: 7.1266e-05\n",
      "Epoch 130/200\n",
      "800/800 [==============================] - 0s 276us/sample - loss: 6.1443e-05 - val_loss: 6.2494e-05\n",
      "Epoch 131/200\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 5.5685e-05 - val_loss: 5.9194e-05\n",
      "Epoch 132/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 253us/sample - loss: 5.0520e-05 - val_loss: 5.1313e-05\n",
      "Epoch 133/200\n",
      "800/800 [==============================] - 0s 242us/sample - loss: 4.4890e-05 - val_loss: 4.5601e-05\n",
      "Epoch 134/200\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 3.9365e-05 - val_loss: 3.8662e-05\n",
      "Epoch 135/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 3.5088e-05 - val_loss: 3.4016e-05\n",
      "Epoch 136/200\n",
      "800/800 [==============================] - 0s 262us/sample - loss: 3.0175e-05 - val_loss: 2.9718e-05\n",
      "Epoch 137/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 2.6134e-05 - val_loss: 2.7104e-05\n",
      "Epoch 138/200\n",
      "800/800 [==============================] - 0s 246us/sample - loss: 2.3526e-05 - val_loss: 2.3144e-05\n",
      "Epoch 139/200\n",
      "800/800 [==============================] - 0s 263us/sample - loss: 1.9592e-05 - val_loss: 1.8985e-05\n",
      "Epoch 140/200\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 1.6680e-05 - val_loss: 1.7465e-05\n",
      "Epoch 141/200\n",
      "800/800 [==============================] - 0s 244us/sample - loss: 1.4171e-05 - val_loss: 1.3909e-05\n",
      "Epoch 142/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 1.1884e-05 - val_loss: 1.1416e-05\n",
      "Epoch 143/200\n",
      "800/800 [==============================] - 0s 241us/sample - loss: 1.0057e-05 - val_loss: 1.0355e-05\n",
      "Epoch 144/200\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 8.6099e-06 - val_loss: 8.2019e-06\n",
      "Epoch 145/200\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 6.8144e-06 - val_loss: 6.3332e-06\n",
      "Epoch 146/200\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 5.3596e-06 - val_loss: 5.0407e-06\n",
      "Epoch 147/200\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 4.2957e-06 - val_loss: 4.0364e-06\n",
      "Epoch 148/200\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 3.4363e-06 - val_loss: 3.1637e-06\n",
      "Epoch 149/200\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 2.7654e-06 - val_loss: 2.4289e-06\n",
      "Epoch 150/200\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 2.0581e-06 - val_loss: 1.9092e-06\n",
      "Epoch 151/200\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 1.5502e-06 - val_loss: 1.3920e-06\n",
      "Epoch 152/200\n",
      "800/800 [==============================] - 0s 246us/sample - loss: 1.1954e-06 - val_loss: 1.0463e-06\n",
      "Epoch 153/200\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 8.5608e-07 - val_loss: 7.4459e-07\n",
      "Epoch 154/200\n",
      "800/800 [==============================] - 0s 244us/sample - loss: 6.2265e-07 - val_loss: 5.4896e-07\n",
      "Epoch 155/200\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 4.4462e-07 - val_loss: 3.7695e-07\n",
      "Epoch 156/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 3.1125e-07 - val_loss: 2.6716e-07\n",
      "Epoch 157/200\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 2.1664e-07 - val_loss: 1.8795e-07\n",
      "Epoch 158/200\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 1.4624e-07 - val_loss: 1.1936e-07\n",
      "Epoch 159/200\n",
      "800/800 [==============================] - 0s 250us/sample - loss: 9.3406e-08 - val_loss: 7.5309e-08\n",
      "Epoch 160/200\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 6.1428e-08 - val_loss: 4.9663e-08\n",
      "Epoch 161/200\n",
      "800/800 [==============================] - 0s 261us/sample - loss: 4.2512e-08 - val_loss: 3.0676e-08\n",
      "Epoch 162/200\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 2.2686e-08 - val_loss: 1.8237e-08\n",
      "Epoch 163/200\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 1.3679e-08 - val_loss: 1.0442e-08\n",
      "Epoch 164/200\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 7.9525e-09 - val_loss: 6.3812e-09\n",
      "Epoch 165/200\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 5.2919e-09 - val_loss: 3.3540e-09\n",
      "Epoch 166/200\n",
      "800/800 [==============================] - 0s 268us/sample - loss: 2.4820e-09 - val_loss: 2.8119e-09\n",
      "Epoch 167/200\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 1.5928e-09 - val_loss: 1.0232e-09\n",
      "Epoch 168/200\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 7.0432e-10 - val_loss: 5.8887e-10\n",
      "Epoch 169/200\n",
      "800/800 [==============================] - 0s 246us/sample - loss: 3.7749e-10 - val_loss: 2.4051e-10\n",
      "Epoch 170/200\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 1.6526e-10 - val_loss: 1.4252e-10\n",
      "Epoch 171/200\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 7.5972e-11 - val_loss: 4.7170e-11\n",
      "Epoch 172/200\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 3.8790e-11 - val_loss: 3.4195e-11\n",
      "Epoch 173/200\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 1.6188e-11 - val_loss: 9.3209e-12\n",
      "Epoch 174/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 6.4800e-12 - val_loss: 5.5928e-12\n",
      "Epoch 175/200\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 2.6846e-12 - val_loss: 1.1993e-12\n",
      "Epoch 176/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 8.6704e-13 - val_loss: 5.3333e-13\n",
      "Epoch 177/200\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 3.3253e-13 - val_loss: 1.8822e-13\n",
      "Epoch 178/200\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 1.3188e-13 - val_loss: 5.4499e-14\n",
      "Epoch 179/200\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 6.9207e-14 - val_loss: 4.8175e-14\n",
      "Epoch 180/200\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 4.6896e-14 - val_loss: 2.5295e-14\n",
      "Epoch 181/200\n",
      "800/800 [==============================] - 0s 259us/sample - loss: 3.3182e-14 - val_loss: 2.8706e-14\n",
      "Epoch 182/200\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 2.8599e-14 - val_loss: 2.2951e-14\n",
      "Epoch 183/200\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 2.9949e-14 - val_loss: 3.4035e-14\n",
      "Epoch 184/200\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 3.1317e-14 - val_loss: 5.8833e-14\n",
      "Epoch 185/200\n",
      "800/800 [==============================] - 0s 244us/sample - loss: 2.4194e-14 - val_loss: 2.2595e-14\n",
      "Epoch 186/200\n",
      "800/800 [==============================] - 0s 273us/sample - loss: 2.2968e-14 - val_loss: 2.3803e-14\n",
      "Epoch 187/200\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 2.0055e-14 - val_loss: 1.0800e-14\n",
      "Epoch 188/200\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 1.4655e-14 - val_loss: 1.1013e-14\n",
      "Epoch 189/200\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 1.7497e-14 - val_loss: 1.6698e-14\n",
      "Epoch 190/200\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 2.8439e-14 - val_loss: 1.6058e-14\n",
      "Epoch 191/200\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 1.4317e-14 - val_loss: 1.5632e-14\n",
      "Epoch 192/200\n",
      "800/800 [==============================] - 0s 246us/sample - loss: 1.8137e-14 - val_loss: 1.2719e-14\n",
      "Epoch 193/200\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 4.4125e-14 - val_loss: 7.9581e-15\n",
      "Epoch 194/200\n",
      "800/800 [==============================] - 0s 264us/sample - loss: 4.6452e-14 - val_loss: 1.3074e-14\n",
      "Epoch 195/200\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 2.2897e-14 - val_loss: 2.3306e-14\n",
      "Epoch 196/200\n",
      "800/800 [==============================] - 0s 261us/sample - loss: 4.1425e-14 - val_loss: 1.9824e-14\n",
      "Epoch 197/200\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 2.6574e-14 - val_loss: 5.9401e-14\n",
      "Epoch 198/200\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 3.1672e-14 - val_loss: 9.6918e-14\n",
      "Epoch 199/200\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 4.4587e-14 - val_loss: 2.6084e-13\n",
      "Epoch 200/200\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 3.8280e-14 - val_loss: 3.3964e-14\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared_weights\n",
      " [array([[1.9999995]], dtype=float32), array([0.9999998], dtype=float32)] \n",
      "\n",
      "y_weights\n",
      " [array([[1.9999999]], dtype=float32), array([1.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "a = 2; b = 1; c = 2; d = 1\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))\n",
    "\n",
    "x_train_A = np.random.rand(1000,1) * 2 - 1\n",
    "x_train_B = np.random.rand(1000,1) * 2 - 1\n",
    "y_train = c * sigmoid(a * x_train_A + b) * sigmoid(a * x_train_B + b) + d\n",
    "\n",
    "shared_layer = layers.Dense(1, activation='sigmoid', name='shared')\n",
    "\n",
    "xA = layers.Input((1,), name='xA')\n",
    "xB = layers.Input((1,), name='xB')\n",
    "sA = shared_layer(xA)\n",
    "sB = shared_layer(xB)\n",
    "mul = layers.Multiply(name='mul')([sA, sB])\n",
    "y = layers.Dense(1, name='y')(mul)\n",
    "\n",
    "model = models.Model([xA, xB], y)\n",
    "model.summary()\n",
    "\n",
    "model.compile('adam', 'mse')\n",
    "hist = model.fit([x_train_A, x_train_B], y_train,\n",
    "                 batch_size=8, epochs=200, validation_split=0.2)\n",
    "\n",
    "plt.title('Loss')\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc=0)\n",
    "plt.show()\n",
    "\n",
    "shared_weights = model.get_layer('shared').get_weights()\n",
    "y_weights = model.get_layer('y').get_weights()\n",
    "print('shared_weights\\n', shared_weights, '\\n')\n",
    "print('y_weights\\n', y_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
